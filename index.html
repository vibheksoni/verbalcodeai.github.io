<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="VerbalCodeAI: A free, open-source AI code assistant to navigate and understand codebases in your terminal. Download now!">
    <meta name="keywords"
        content="VerbalCodeAI, AI coding tool, codebase navigation, open-source, programming, developer tools">
    <title>VerbalCodeAI - Your AI Coding Companion</title>
    <link rel="icon" href="assets/images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Roboto+Mono:wght@400;700&display=swap"
        rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/ScrollTrigger.min.js"></script>
</head>

<body>
    <nav>
        <div class="container">
            <div class="nav-container">
                <a href="#" class="logo">VerbalCodeAI</a>
                <button id="mobile-menu-toggle" class="mobile-menu-button">
                    <span class="menu-icon"></span>
                </button>
            </div>
            <div class="nav-links" id="nav-links">
                <a href="#features">Features</a>
                <a href="#how-it-works">How it Works</a>
                <a href="#getting-started">Getting Started</a>
                <a href="#integrations">Integrations</a>
                <a href="#configuration">Configuration</a>
                <a href="https://discord.gg/KpjSDEwWCF" target="_blank" class="btn">Discord</a>
                <a href="https://github.com/vibheksoni/VerbalCodeAi" target="_blank" class="btn">GitHub</a>
            </div>
        </div>
    </nav>

    <header>
        <div class="container">
            <div class="hero">
                <h1>VerbalCodeAI</h1>
                <p class="tagline">Understand Your Code. Instantly.</p>
                <div class="hero-showcase-gif" style="text-align: center; margin-bottom: 20px;">
                    <img src="assets/images/VerbalCodeShowcase.gif" alt="VerbalCodeAI Showcase" style="max-width: 800px; max-height: 400px; width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                </div>
                <div class="badges">
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/stargazers" target="_blank"><img
                            src="https://img.shields.io/github/stars/vibheksoni/VerbalCodeAi?style=social"
                            alt="GitHub stars"></a>
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/network/members" target="_blank"><img
                            src="https://img.shields.io/github/forks/vibheksoni/VerbalCodeAi?style=social"
                            alt="GitHub forks"></a>
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/issues" target="_blank"><img
                            src="https://img.shields.io/github/issues/vibheksoni/VerbalCodeAi" alt="GitHub issues"></a>
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/blob/master/LICENSE" target="_blank"><img
                            src="https://img.shields.io/github/license/vibheksoni/VerbalCodeAi" alt="GitHub license"></a>
                    <a href="https://www.python.org/downloads/release/python-3116/" target="_blank"><img
                            src="https://img.shields.io/badge/python-3.11.6-blue" alt="Python Version"></a>
                    <a href="https://verbalcode.xyz" target="_blank"><img
                            src="https://img.shields.io/badge/website-verbalcode.xyz-brightgreen" alt="Website"></a>
                </div>
                <div class="ascii-art">
_   _ _______  ______ ______  _______             _______  _____  ______  _______      _______ _____
\  /  |______ |_____/ |_____] |_____| |           |       |     | |     \ |______      |_____|   |  
 \/   |______ |    \_ |_____] |     | |_____      |_____  |_____| |_____/ |______      |     | __|__
    
        [AI Assistant for Code]
                </div>
                <p class="description">
                    Ever felt lost in a complex codebase? VerbalCodeAI is your personal code companion, leveraging advanced embedding techniques and Large Language Model (LLM) integration. It offers intelligent code analysis, helps you search and understand your project, and provides assistance directly within your command-line interface, making your development workflow smoother and more efficient.
                </p>
                <div class="cta-buttons">
                    <a href="https://github.com/vibheksoni/VerbalCodeAi" target="_blank" class="btn primary">Get Started
                        (It's Free!)</a>
                    <a href="#features" class="btn secondary">Learn More</a>
                </div>
                
                <div class="discord-banner">
                    <h3>Join Our Discord Community!</h3>
                    <p>We're looking for help setting up and moderating our server. If you're experienced with Discord setup, your assistance would be greatly appreciated!</p>
                    <a href="https://discord.gg/KpjSDEwWCF" target="_blank" class="btn primary">Join Discord</a>
                </div>
            </div>
        </div>
    </header>

    <section id="features">
        <div class="container">
            <h2>‚ú® Features</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h3>üîç Intelligent Code Search</h3>
                    <p>Find relevant code snippets using natural language queries</p>
                </div>
                <div class="feature-card">
                    <h3>üìä Code Analysis</h3>
                    <p>Get insights about your codebase structure and dependencies</p>
                </div>
                <div class="feature-card">
                    <h3>ü§ñ Agent Mode</h3>
                    <p>Let the AI explore and understand your codebase using various tools</p>
                </div>
                <div class="feature-card">
                    <h3>üí¨ Chat with AI</h3>
                    <p>Ask questions about your code and get detailed explanations</p>
                </div>
                <div class="feature-card">
                    <h3>üåê Web Search Integration</h3>
                    <p>Search the web for code-related information without leaving the terminal</p>
                </div>
                <div class="feature-card">
                    <h3>üß† Memory System</h3>
                    <p>The AI remembers important information about your project</p>
                </div>
                <div class="feature-card">
                    <h3>üîÑ Version Control Integration</h3>
                    <p>Analyze git history and changes</p>
                </div>
                <div class="feature-card">
                    <h3>üìù File Description</h3>
                    <p>Generate concise descriptions of code files</p>
                </div>
                <div class="feature-card">
                    <h3>üõ†Ô∏è Command Runner</h3>
                    <p>Execute system commands with AI assistance</p>
                </div>
                <div class="feature-card">
                    <h3>üîå HTTP API Server</h3>
                    <p>Integrate with other tools via the built-in HTTP API</p>
                </div>
                <div class="feature-card">
                    <h3>ü§ù MCP Integration</h3>
                    <p>Connect with Claude Desktop and other MCP-compatible AI assistants</p>
                </div>
                <div class="feature-card">
                    <h3>üîß Customizable</h3>
                    <p>Configure LLM providers, models, and behavior to suit your needs</p>
                </div>
            </div>
        </div>
    </section>

    <section id="how-it-works">
        <div class="container">
            <h2>üîç How it Works</h2>

            <div class="process-overview">
                <h3>The Indexing Process</h3>
                <p>When you first use VerbalCodeAI, it indexes your codebase to create searchable resources:</p>

                <div class="index-folders">
                    <div class="folder-item">
                        <h4>Code Embeddings</h4>
                        <p>VerbalCodeAI analyzes your code files and generates vector embeddings, enabling semantic search capabilities.</p>
                    </div>
                    <div class="folder-item">
                        <h4>File Metadata</h4>
                        <p>Information about file types, sizes, and structure is collected to help with navigation and search.</p>
                    </div>
                    <div class="folder-item">
                        <h4>Code Structure</h4>
                        <p>Functions, classes, and imports are identified and indexed for quick reference.</p>
                    </div>
                </div>
            </div>

            <div class="chat-modes">
                <h3>Interaction Modes</h3>
                <p>VerbalCodeAI offers two powerful ways to interact with your code:</p>

                <div class="mode-grid">
                    <div class="mode-card">
                        <h4>Chat Mode</h4>
                        <p>Have natural conversations about your code:</p>
                        <ul>
                            <li>Ask questions about code functionality</li>
                            <li>Request explanations of complex sections</li>
                            <li>Get suggestions for improvements</li>
                            <li>Understand dependencies and relationships</li>
                        </ul>
                    </div>
                    <div class="mode-card">
                        <h4>Agent Mode</h4>
                        <p>Let the AI use tools to explore your codebase:</p>
                        <ul>
                            <li>Search for specific code patterns</li>
                            <li>Analyze code structure and dependencies</li>
                            <li>Execute commands to test functionality</li>
                            <li>Access web resources for additional context</li>
                            <li>Generate comprehensive reports</li>
                        </ul>
                        <div class="pro-tip" style="background-color: var(--note-bg-color); border-left: 4px solid var(--accent-color); padding: 1rem; margin: 0.5rem 0; border-radius: 0 4px 4px 0;">
                            <p><strong>üí° Pro Tip:</strong> Agent Mode is more cost-effective when using cloud-based LLM providers as it makes fewer API calls.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="getting-started">
        <div class="container">
            <h2>üöÄ Getting Started</h2>

            <h3>Prerequisites</h3>
            <ul>
                <li>Python 3.11.6 (tested and recommended version)</li>
                <li><a href="https://ollama.com/download" target="_blank">Ollama</a> (for local model execution)</li>
            </ul>

            <div class="note">
                <strong>Note:</strong> The application has been specifically tested with Python 3.11.6 on Windows.
                While it may work with other versions, for the best experience, we recommend using the tested
                version.
            </div>

            <h3>Installation</h3>

            <h4>Windows</h4>
            <div class="code-block">
                <pre><code>git clone https://github.com/vibheksoni/VerbalCodeAi.git
cd VerbalCodeAi
setup_windows.bat</code></pre>
            </div>

            <h4>Linux/macOS</h4>
            <div class="code-block">
                <pre><code>git clone https://github.com/vibheksoni/VerbalCodeAi.git
cd VerbalCodeAi
chmod +x setup_linux.sh
./setup_linux.sh</code></pre>
            </div>

            <h3>Manual Installation</h3>
            <p>If you prefer to set up manually:</p>
            <ol>
                <li>
                    Create a virtual environment:
                    <div class="code-block">
                        <pre><code>python -m venv venv</code></pre>
                    </div>
                </li>
                <li>
                    Activate the virtual environment:
                    <ul>
                        <li>Windows: <code>venv\Scripts\activate</code></li>
                        <li>Linux/macOS: <code>source venv/bin/activate</code></li>
                    </ul>
                </li>
                <li>
                    Install dependencies:
                    <div class="code-block">
                        <pre><code>pip install -r requirements.txt</code></pre>
                    </div>
                </li>
                <li>Create a <code>.env</code> file with your configuration (see <code>.env.example</code> for
                        reference)</li>
            </ol>

            <h3>Usage</h3>

            <h4>Starting the Application</h4>
            <p>After installation, activate your virtual environment and run:</p>
            <div class="code-block">
                <pre><code>python app.py</code></pre>
            </div>

            <h4>Indexing a Project</h4>
            <p>When you first start VerbalCodeAI, you'll be prompted to select a directory to index. This process
                analyzes your codebase and creates embeddings for efficient searching.</p>

            <h4>Main Menu Options</h4>
            <ul>
                <li><strong>Chat with AI</strong>: Ask questions about your code</li>
                <li><strong>Agent Mode</strong>: Use AI with tools to explore your codebase</li>
                <li><strong>Reindex Project</strong>: Update the index after code changes</li>
                <li><strong>Project Info</strong>: View information about the indexed project</li>
                <li><strong>Settings</strong>: Configure application settings</li>
                <li><strong>Exit</strong>: Quit the application</li>
            </ul>
        </div>
    </section>

    <section id="agent-tools">
        <div class="container">
            <h2>Agent Mode Tools</h2>
            <p>Agent Mode provides access to powerful tools:</p>

            <div class="tools-grid">
                <div class="tool-category">
                    <h3>Search Tools</h3>
                    <ul>
                        <li><code>embed_search</code></li>
                        <li><code>semantic_search</code></li>
                        <li><code>grep</code></li>
                        <li><code>regex_advanced_search</code></li>
                        <li><code>file_type_search</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>File Tools</h3>
                    <ul>
                        <li><code>read_file</code></li>
                        <li><code>file_stats</code></li>
                        <li><code>directory_tree</code></li>
                        <li><code>get_file_description</code></li>
                        <li><code>get_file_metadata</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Code Analysis</h3>
                    <ul>
                        <li><code>find_functions</code></li>
                        <li><code>find_classes</code></li>
                        <li><code>find_usage</code></li>
                        <li><code>cross_reference</code></li>
                        <li><code>code_analysis</code></li>
                        <li><code>get_functions</code></li>
                        <li><code>get_classes</code></li>
                        <li><code>get_variables</code></li>
                        <li><code>get_imports</code></li>
                        <li><code>explain_code</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Version Control</h3>
                    <ul>
                        <li><code>git_history</code></li>
                        <li><code>version_control_search</code></li>
                        <li><code>search_imports</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Project Tools</h3>
                    <ul>
                        <li><code>get_project_description</code></li>
                        <li><code>get_instructions</code></li>
                        <li><code>create_instructions_template</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Memory Tools</h3>
                    <ul>
                        <li><code>add_memory</code></li>
                        <li><code>get_memories</code></li>
                        <li><code>search_memories</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>System Tools</h3>
                    <ul>
                        <li><code>run_command</code></li>
                        <li><code>read_terminal</code></li>
                        <li><code>kill_terminal</code></li>
                        <li><code>list_terminals</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Helper Tools</h3>
                    <ul>
                        <li><code>ask_buddy</code> (with context-aware second opinions)</li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Web Tools</h3>
                    <ul>
                        <li><code>google_search</code></li>
                        <li><code>ddg_search</code></li>
                        <li><code>bing_news_search</code></li>
                        <li><code>fetch_webpage</code></li>
                        <li><code>get_base_knowledge</code></li>
                    </ul>
                </div>
            </div>

            <div class="pro-tip" style="background-color: var(--note-bg-color); border-left: 4px solid var(--accent-color); padding: 1rem; margin: 1.5rem 0; border-radius: 0 4px 4px 0;">
                <h5 style="color: var(--accent-color); margin-top: 0;">üí° Pro Tip</h5>
                <p>Agent Mode is the most cost-effective option when using cloud-based LLM providers. It makes fewer API calls compared to Chat Mode, which helps avoid rate limits and reduces costs. For the best experience with minimal expenses, consider using Agent Mode when working with paid API services.</p>
            </div>
        </div>    
    </section>

    <section id="integrations">
        <div class="container">
            <h2>üîå HTTP API Server</h2>
            <p>VerbalCodeAI includes a built-in HTTP API server that allows you to access its functionality programmatically. This is useful for integrating VerbalCodeAI with other tools or creating custom interfaces.</p>
            
            <h3>Starting the HTTP API Server</h3>
            <p>To start the HTTP API server:</p>
            <div class="code-block">
                <pre><code>python app.py --serve [PORT]</code></pre>
            </div>
            <p>Where <code>[PORT]</code> is the port number you want the server to listen on (default is 8000).</p>
            
            <h3>API Endpoints</h3>
            <p>The HTTP API server exposes several endpoints:</p>
            <div class="code-block">
                <pre><code>GET    /api/health             - Health check endpoint
POST   /api/initialize         - Initialize a directory
POST   /api/ask                - Ask a question about the code
POST   /api/index/start        - Start indexing a directory
GET    /api/index/status       - Get indexing status</code></pre>
            </div>
            
            <h3>Example Usage</h3>
            <p>Here's an example of how to use the API with cURL:</p>
            <div class="code-block">
                <pre><code>curl -X POST http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What does the main function do in this project?"}'</code></pre>
            </div>
            
            <div class="note">
                <strong>Note:</strong> By default, the server only accepts connections from localhost (127.0.0.1). To allow connections from any IP address, set the <code>HTTP_ALLOW_ALL_ORIGINS</code> environment variable to <code>TRUE</code> in your <code>.env</code> file.
            </div>
        </div>
    </section>

    <section id="mcp-integration">
        <div class="container">
            <h2>ü§ù MCP Integration</h2>
            <p>VerbalCodeAI supports the Model Context Protocol (MCP), allowing you to connect it to Claude Desktop and other MCP-compatible AI assistants. This integration enables Claude to directly interact with your codebase, providing a powerful AI-assisted development experience.</p>            <div class="mcp-showcase-gallery">
                <div class="mcp-showcase-item">
                    <div class="image-container">
                        <img src="assets/images/MCP Showcase.PNG" alt="MCP Integration with Claude Desktop"
                            class="mcp-showcase-image">
                    </div>
                    <p class="image-caption">Claude Desktop MCP Integration</p>
                </div>
                <div class="mcp-showcase-item">
                    <div class="image-container">
                        <img src="assets/images/MCP Showcase 2.PNG" alt="MCP Showcase - Example 2" 
                            class="mcp-showcase-image">
                    </div>
                    <p class="image-caption">Claude analyzing code with VerbalCodeAI</p>
                </div>
            </div>

            <h3>Setting Up the MCP Server</h3>
            <p>The MCP server wraps the HTTP API server and provides tools for Claude to interact with VerbalCodeAI. Here's how to set it up:</p>
            <ol>
                <li>
                    <strong>Start the HTTP API Server</strong>:
                    <p>First, start the HTTP API server if it's not already running:</p>
                    <div class="code-block">
                        <pre><code>python app.py --serve [PORT]</code></pre>
                    </div>
                    <p>Where <code>[PORT]</code> is the port number you want the server to listen on (default is 8000).</p>
                </li>
                <li>
                    <strong>Start the MCP Server</strong>:
                    <p>In a new terminal window, start the MCP server:</p>
                    <div class="code-block">
                        <pre><code>python mcp_server.py</code></pre>
                    </div>
                    <p>The MCP server will automatically check if the HTTP API server is running and start it if needed.</p>
                </li>
                <li>
                    <strong>Configure the MCP Server (Optional)</strong>:
                    <p>You can configure the MCP server by setting the following environment variables in your <code>.env</code> file:</p>
                    <div class="code-block">
                        <pre><code>MCP_API_URL=http://localhost:8000  # URL of the HTTP API server
MCP_HTTP_PORT=8000               # Port to run the HTTP API server on</code></pre>
                    </div>
                </li>
            </ol>

            <h3>Using with Claude Desktop</h3>
            <p>To use VerbalCodeAI with Claude Desktop:</p>
            <ol>
                <li>
                    <strong>Install Dependencies</strong>:
                    <p>Ensure all necessary dependencies are installed by running the following command in the repository's root directory:</p>
                    <div class="code-block">
                        <pre><code>pip install -r requirements.txt</code></pre>
                    </div>
                </li>
                <li>
                    <strong>Install the MCP Server in Claude Desktop</strong>:
                    <p>(Instructions for this step would typically involve placing the server files in a specific directory or using a Claude Desktop interface if available. Refer to Claude Desktop documentation for specifics.)</p>
                    <p>Restart Claude Desktop for the changes to take effect.</p>
                </li>
                <li>
                    <strong>Open Claude Desktop</strong>:
                    <ul>
                        <li>Launch Claude Desktop</li>
                        <li>Select "VerbalCodeAI" from the list of available tools</li>
                    </ul>
                </li>
                <li>
                    <strong>Initialize a Project</strong>:
                    <p>In Claude Desktop, you can now use the following tools:</p>
                    <div class="code-block">
                        <pre><code>set_api_url(url: str) -> str
health_check() -> Dict[str, str]
start_http_server_tool(port: int = None) -> Dict[str, str]
initialize_directory(directory_path: str) -> Dict[str, str]
ask_agent(question: str) -> Dict[str, str]
start_indexing(directory_path: str) -> Dict[str, str]
get_indexing_status() -> Dict[str, str]</code></pre>
                    </div>
                </li>
            </ol>

            <h3>Using with Cursor</h3>
            <p><a href="https://cursor.sh/" target="_blank">Cursor</a> is an AI-powered code editor that supports MCP. To use VerbalCodeAI with Cursor:</p>
            <ol>
                <li><strong>Install Cursor</strong> if you haven't already from <a href="https://cursor.sh/" target="_blank">cursor.sh</a></li>
                <li>
                    <strong>Start the MCP Server</strong>:
                    <div class="code-block">
                        <pre><code>python mcp_server.py</code></pre>
                    </div>
                </li>
                <li>
                    <strong>Connect Cursor to the MCP Server</strong>:
                    <ul>
                        <li>Open Cursor</li>
                        <li>Select "VerbalCodeAI" from the list of available tools (refer to Cursor documentation for specific steps).</li>
                    </ul>
                </li>
                <li>
                    <strong>Use VerbalCodeAI in Cursor</strong>:
                    <ul>
                        <li>Open your project in Cursor</li>
                        <li>You can ask questions about your codebase, get explanations, and more.</li>
                    </ul>
                </li>
            </ol>
        </div>
    </section>

    <section id="configuration">
        <div class="container">
            <h2>‚öôÔ∏è Configuration</h2>
            <p>VerbalCodeAI can be configured through the <code>.env</code> file:</p><div class="code-block">
                <pre><code># Provider can be: ollama, google, openai, anthropic, groq, or openrouter
AI_CHAT_PROVIDER=ollama
AI_EMBEDDING_PROVIDER=ollama
AI_DESCRIPTION_PROVIDER=ollama
AI_AGENT_BUDDY_PROVIDER=ollama

# API Keys for each functionality (only needed if using that provider)
# The same key will be used for the selected provider in each category
AI_CHAT_API_KEY=None
AI_EMBEDDING_API_KEY=None
AI_DESCRIPTION_API_KEY=None
AI_AGENT_BUDDY_API_KEY=None

# Azure OpenAI
# when using openai as a provider and you want to use Azure OpenAI, set these variables
# the endpoint should be in the format: https://<your-resource-name>.openai.azure.com/
AZURE_OPENAI_ENDPOINT=None
# The API version to access your OpenAI resource. E.g. 2024-07-01-preview
OPENAI_API_VERSION=None

# Model names for each provider
# For ollama: llama2, codellama, mistral, etc. (embedding)
# For OpenAI: gpt-4, gpt-3.5-turbo, text-embedding-ada-002 (embedding)
# For OpenRouter: anthropic/claude-3-opus, openai/gpt-4-turbo, google/gemini-pro, etc.
# For Google: gemini-pro, gemini-pro-vision
# For Anthropic: claude-3-5-sonnet-latest, claude-3-opus-20240229, claude-3-haiku-20240307
# For Groq: llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768
CHAT_MODEL=llama2
EMBEDDING_MODEL=all-minilm:33m
DESCRIPTION_MODEL=llama2
AI_AGENT_BUDDY_MODEL=llama3.2

# Optional: Site information for OpenRouter rankings
SITE_URL=http://localhost:3000
SITE_NAME=Local Development

# Performance settings (LOW, MEDIUM, MAX)
# LOW: Minimal resource usage, suitable for low-end systems
# MEDIUM: Balanced resource usage, suitable for most systems
# MAX: Maximum resource usage, suitable for high-end systems
PERFORMANCE_MODE=MEDIUM
# Maximum number of threads to use (will be calculated automatically if not set)
MAX_THREADS=16
# Cache size for embedding queries (higher values use more memory but improve performance)
EMBEDDING_CACHE_SIZE=1000
# Similarity threshold for embedding search (lower values return more results but may be less relevant)
EMBEDDING_SIMILARITY_THRESHOLD=0.05

# API Rate Limiting Settings
# Delay in milliseconds between embedding API calls to prevent rate limiting
# Recommended: 100ms for Google, 0ms for OpenAI/Ollama (set to 0 to disable)
EMBEDDING_API_DELAY_MS=100
# Delay in milliseconds between description generation API calls to prevent rate limiting
# Recommended: 100ms for Google, 0ms for OpenAI/Ollama (set to 0 to disable)
DESCRIPTION_API_DELAY_MS=100

# UI Settings
# Enable/disable markdown rendering (TRUE/FALSE)
ENABLE_MARKDOWN_RENDERING=TRUE
# Show thinking blocks in AI responses (TRUE/FALSE)
SHOW_THINKING_BLOCKS=FALSE
# Enable streaming mode for AI responses (TRUE/FALSE) # Tends to be slower for some reason # Broken for openrouter TODO: Fix this at some point !
ENABLE_STREAMING_MODE=FALSE
# Enable chat logging to save conversations (TRUE/FALSE)
CHAT_LOGS=FALSE
# Enable memory for AI conversations (TRUE/FALSE)
MEMORY_ENABLED=TRUE
# Maximum number of memory items to store
MAX_MEMORY_ITEMS=10
# Execute commands without confirmation (TRUE/FALSE)
# When FALSE, the user will be prompted to confirm before executing any command
# When TRUE, commands will execute automatically without confirmation
COMMANDS_YOLO=FALSE

# HTTP API Server Settings
# Allow connections from any IP address (TRUE/FALSE)
# When FALSE, the server only accepts connections from localhost (127.0.0.1)
# When TRUE, the server accepts connections from any IP address (0.0.0.0)
# WARNING: Setting this to TRUE may expose your API to the internet
HTTP_ALLOW_ALL_ORIGINS=FALSE

# MCP Server Settings
# URL of the HTTP API server
MCP_API_URL=http://localhost:8000
# Port to run the HTTP API server on
MCP_HTTP_PORT=8000
</code></pre>
            </div><h3>Supported LLM Providers</h3>
            <ul style="list-style-type: none; padding-left: 0;">
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://media.licdn.com/dms/image/v2/D5612AQEOULWgnVbBRA/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1713098774047?e=2147483647&v=beta&t=ci_6MctI3jG8VK_mPNiyGuno_3ePW_IEJKCjACj2gCg" alt="Ollama logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Ollama</strong>: Local models (default)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://logos-world.net/wp-content/uploads/2023/05/Google-Bard-AI-Logo.png" alt="Google AI logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Google AI</strong>: Cloud-based models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/openai-old-logo.png?quality=90&strip=all&crop=7.8125%2C0%2C84.375%2C100&w=2400" alt="OpenAI logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>OpenAI</strong>: OpenAI models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcROScdzQQ7P9TpyyBE4qlB43zKKpesGArmB1w&s" alt="Anthropic logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Anthropic</strong>: Claude 3 models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);"></li>
                    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRHVsO5kFrri_uqZdlB6mACC2bdyyy6D0bYag&s" alt="Groq logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Groq</strong>: Fast inference for Mixtral and LLama models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://pbs.twimg.com/profile_images/1682268668321726464/NEb6_n7n_400x400.jpg" alt="OpenRouter logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>OpenRouter</strong>: Various cloud models (requires API key)</div>
                </li>
            </ul>
            
            <div class="provider-details">
                <div class="provider-card">
                    <h4>Recommended Ollama Setup</h4>
                    <p>For the best local experience without any API costs, the developer recommends using these Ollama models:</p>
                    <ul>
                        <li><strong>Chat/Description</strong>: <code>gemma3</code> - Google's Gemma 3 model provides excellent code understanding and generation</li>
                        <li><strong>Embeddings</strong>: <code>all-minilm</code> - Efficient and accurate embeddings for code search and retrieval</li>
                    </ul>
                    <div class="code-block">
                        <pre><code># Install the recommended models
ollama pull gemma3
ollama pull all-minilm

# Configure in .env
AI_CHAT_PROVIDER=ollama
AI_EMBEDDING_PROVIDER=ollama
AI_DESCRIPTION_PROVIDER=ollama
CHAT_MODEL=gemma3
EMBEDDING_MODEL=all-minilm:33m
DESCRIPTION_MODEL=gemma3</code></pre>
                    </div>
                </div>

                <div class="provider-card">
                    <h4>Anthropic Claude Models</h4>
                    <p>Anthropic's Claude models are particularly strong at understanding and generating code. Available models include:</p>
                    <ul>
                        <li><strong>claude-3-5-sonnet-latest</strong>: Latest version of Claude 3.5 Sonnet, excellent balance of performance and speed</li>
                        <li><strong>claude-3-opus-20240229</strong>: Most powerful Claude model with advanced reasoning capabilities</li>
                        <li><strong>claude-3-haiku-20240307</strong>: Fastest and most cost-effective Claude model</li>
                    </ul>
                    <p>Note: Anthropic does not provide embedding capabilities, so you'll need to use a different provider for embeddings.</p>
                </div>

                <div class="provider-card">
                    <h4>Groq Models</h4>
                    <p>Groq provides ultra-fast inference for popular open-source models. Available models include:</p>
                    <ul>
                        <li><strong>llama3-8b-8192</strong>: Smaller Llama 3 model with 8B parameters, good balance of performance and speed</li>
                        <li><strong>llama3-70b-8192</strong>: Larger Llama 3 model with 70B parameters, excellent reasoning capabilities</li>
                        <li><strong>mixtral-8x7b-32768</strong>: Mixtral model with 8x7B parameters and 32k context window</li>
                    </ul>
                    <p>Note: Groq does not provide embedding capabilities, so you'll need to use a different provider for embeddings.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="project-structure">
        <div class="container">
            <h2>üß© Project Structure</h2>            <div class="code-block">
                <pre><code>VerbalCodeAi/
‚îú‚îÄ‚îÄ app.py                  # Main application entry point
‚îú‚îÄ‚îÄ mcp_server.py           # MCP server wrapper
‚îú‚îÄ‚îÄ mcp_server_http.py      # HTTP-based MCP server implementation
‚îú‚îÄ‚îÄ mods/                   # Core modules
‚îÇ   ‚îú‚îÄ‚îÄ banners.py          # ASCII art banners
‚îÇ   ‚îú‚îÄ‚îÄ http_api.py         # HTTP API server implementation
‚îÇ   ‚îú‚îÄ‚îÄ llms.py             # LLM integration
‚îÇ   ‚îú‚îÄ‚îÄ terminal_ui.py      # Terminal UI components
‚îÇ   ‚îú‚îÄ‚îÄ terminal_utils.py   # Terminal utilities
‚îÇ   ‚îî‚îÄ‚îÄ code/               # Code processing modules
‚îÇ       ‚îú‚îÄ‚îÄ agent_mode.py   # Agent mode implementation
‚îÇ       ‚îú‚îÄ‚îÄ decisions.py    # AI decision making
‚îÇ       ‚îú‚îÄ‚îÄ directory.py    # Directory structure handling
‚îÇ       ‚îú‚îÄ‚îÄ embed.py        # Embedding generation and search
‚îÇ       ‚îú‚îÄ‚îÄ indexer.py      # File indexing
‚îÇ       ‚îú‚îÄ‚îÄ memory.py       # Memory management
‚îÇ       ‚îú‚îÄ‚îÄ terminal.py     # Terminal command execution
‚îÇ       ‚îî‚îÄ‚îÄ tools.py        # Agent tools
‚îú‚îÄ‚îÄ integrations/           # IDE and tool integrations
‚îÇ   ‚îú‚îÄ‚îÄ claude/             # Claude Desktop integration
‚îÇ   ‚îú‚îÄ‚îÄ cursor/             # Cursor editor integration
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Integration documentation
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ setup_windows.bat       # Windows setup script
‚îî‚îÄ‚îÄ setup_linux.sh          # Linux setup script</code></pre>
            </div>
        </div>
    </section>    <section id="community">
        <div class="container">
            <h2>üë• Community</h2>
            <p>Join our growing community of developers using VerbalCodeAI!</p>
            
            <div class="discord-card">
                <h3>Discord Server</h3>
                <p>Join our Discord server to:</p>
                <ul>
                    <li>Get help with installation and configuration</li>
                    <li>Share your use cases and tips</li>
                    <li>Contribute to the project</li>
                    <li>Connect with other developers using VerbalCodeAI</li>
                    <li>Get early access to new features</li>
                </ul>
                <a href="https://discord.gg/KpjSDEwWCF" target="_blank" class="btn primary">Join Discord</a>
            </div>
        </div>
    </section>

    <section id="contributing">
        <div class="container">
            <h2>ü§ù Contributing</h2>
            <p>Contributions are welcome! Please feel free to submit a Pull Request.</p>
            <ol>
                <li>Fork the repository</li>
                <li>Create your feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
                <li>Commit your changes (<code>git commit -m 'Add some amazing feature'</code>)</li>
                <li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li>
                <li>Open a Pull Request</li>
            </ol>

            <h3>Areas Where Help is Needed</h3>
            <ul>
                <li><strong>IDE Integrations</strong>: Help build plugins for VSCode, Neovim, and other editors</li>
                <li><strong>Documentation</strong>: Improve guides and examples</li>
                <li><strong>Testing</strong>: Help test on different platforms and setups</li>
                <li><strong>Feature Development</strong>: Implement new tools and capabilities</li>
            </ul>
        </div>
    </section>

    <section id="license">
        <div class="container">
            <h2>üìù License</h2>
            <p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
        </div>
    </section>

    <section id="links">
        <div class="container">
            <h2>üîó Links</h2>
            <ul>
                <li><a href="https://github.com/vibheksoni/VerbalCodeAi" target="_blank">GitHub Repository</a></li>
                <li><a href="https://github.com/vibheksoni/VerbalCodeAi/issues" target="_blank">Report Issues</a></li>
            </ul>
        </div>
    </section>

    <section id="acknowledgements">
        <div class="container">
            <h2>üôè Acknowledgements</h2>
            <ul></ul>
                <li><a href="https://ollama.com/" target="_blank">Ollama</a> for local model execution</li>
                <li><a href="https://tree-sitter.github.io/tree-sitter/" target="_blank">Tree-sitter</a> for code
                    parsing</li>
                <li>All the open-source libraries that make this project possible</li>
            </ul>
        </div>
    </section>

    <section id="visual-showcase">
        <div class="container">
            <h2>üé¨ Visual Showcase</h2>

            <div class="image-slider">
                <h3>Application Screenshots</h3>
                <div class="slider-container">
                    <img src="assets/images/Agent Showcase.png" alt="VerbalCodeAI Screenshot" id="sliderImage" class="w-full rounded-lg shadow-lg mb-4">
                    <div class="slider-controls">
                        <button id="prevImage" class="btn secondary">&#10094; Previous</button>
                        <button id="nextImage" class="btn secondary">Next &#10095;</button>
                    </div>
                    <p id="imageCaption" class="text-center mt-2">Agent Mode Showcase</p>
                </div>
            </div>

            <div class="video-showcase mt-12">
                <h3>Simple Showcase Video</h3>
                <video controls class="w-full rounded-lg shadow-lg" id="showcaseVideo"
                    poster="assets/images/Agent Showcase.png">
                    <source src="assets/images/Simple Showcase Video.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </div>
    </section>

    <!-- Image Fullscreen Modal -->
    <div id="image-modal" class="image-fullscreen-modal">
        <span class="close-modal">&times;</span>
        <img id="fullscreen-image" class="modal-content">
        <div id="modal-caption"></div>
    </div>

    <footer>
        <div class="container">
            <p>Made with ‚ù§Ô∏è by <a href="https://github.com/vibheksoni" target="_blank">Vibhek Soni</a></p>
            <p>¬© 2024 VerbalCodeAI. All rights reserved.</p>
        </div>
    </footer>

    <script src="assets/js/animations.js"></script>
    <script>
        // Mobile menu toggle
        document.addEventListener('DOMContentLoaded', function() {
            const menuButton = document.getElementById('mobile-menu-toggle');
            const navLinks = document.getElementById('nav-links');
            
            if (menuButton && navLinks) {
                menuButton.addEventListener('click', function() {
                    menuButton.classList.toggle('active');
                    navLinks.classList.toggle('active');
                });
                
                // Close menu when clicking on a link
                const links = navLinks.querySelectorAll('a');
                links.forEach(link => {
                    link.addEventListener('click', function() {
                        menuButton.classList.remove('active');
                        navLinks.classList.remove('active');
                    });
                });
            }
        });

        // Image slider functionality
        let currentImageIndex = 0;
        const images = [
            'assets/images/Agent Showcase.png',
            'assets/images/Another Showcase Image.png', // Add more images as needed
        ];

        function showImage(index) {
            const sliderImage = document.getElementById('sliderImage');
            const imageCaption = document.getElementById('imageCaption');
            if (sliderImage && imageCaption) {
                sliderImage.src = images[index];
                imageCaption.textContent = `Image ${index + 1} of ${images.length}`;
            }
        }

        document.getElementById('nextImage').addEventListener('click', function() {
            currentImageIndex = (currentImageIndex + 1) % images.length;
            showImage(currentImageIndex);
        });

        document.getElementById('prevImage').addEventListener('click', function() {
            currentImageIndex = (currentImageIndex - 1 + images.length) % images.length;
            showImage(currentImageIndex);
        });

        // Fullscreen image modal
        const imageModal = document.getElementById('image-modal');
        const fullscreenImage = document.getElementById('fullscreen-image');
        const closeModal = document.querySelector('.close-modal');

        document.querySelectorAll('.image-container img').forEach(img => {
            img.addEventListener('click', function() {
                const src = this.src;
                const alt = this.alt;
                fullscreenImage.src = src;
                document.getElementById('modal-caption').textContent = alt;
                imageModal.style.display = 'flex';
            });
        });

        closeModal.addEventListener('click', function() {
            imageModal.style.display = 'none';
        });

        window.addEventListener('click', function(event) {
            if (event.target === imageModal) {
                imageModal.style.display = 'none';
            }
        });
    </script>
</body>

</html>