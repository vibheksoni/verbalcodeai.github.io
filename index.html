<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="VerbalCodeAI: A free, open-source AI code assistant to navigate and understand codebases in your terminal. Download now!">
    <meta name="keywords"
        content="VerbalCodeAI, AI coding tool, codebase navigation, open-source, programming, developer tools">
    <title>VerbalCodeAI - Your AI Coding Companion</title>
    <link rel="icon" href="assets/images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Roboto+Mono:wght@400;700&display=swap"
        rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/ScrollTrigger.min.js"></script>
</head>

<body>
    <nav>
        <div class="container">
            <a href="#" class="logo">VerbalCodeAI</a>            <div class="nav-links">
                <a href="#features">Features</a>
                <a href="#how-it-works">How it Works</a>
                <a href="#getting-started">Getting Started</a>
                <a href="#integrations">Integrations</a>
                <a href="#configuration">Configuration</a>
                <a href="https://discord.gg/KpjSDEwWCF" target="_blank" class="btn">Discord</a>
                <a href="https://github.com/vibheksoni/VerbalCodeAi" target="_blank" class="btn">GitHub</a>
            </div>
        </div>
    </nav>

    <header>
        <div class="container">
            <div class="hero">
                <h1>VerbalCodeAI</h1>
                <p class="tagline">Understand Your Code. Instantly.</p>
                <div class="hero-showcase-gif" style="text-align: center; margin-bottom: 20px;">
                    <img src="assets/images/VerbalCodeShowcase.gif" alt="VerbalCodeAI Showcase" style="max-width: 800px; max-height: 400px; width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                </div>
                <div class="badges">
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/stargazers" target="_blank"><img
                            src="https://img.shields.io/github/stars/vibheksoni/VerbalCodeAi?style=social"
                            alt="GitHub stars"></a>
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/network/members" target="_blank"><img
                            src="https://img.shields.io/github/forks/vibheksoni/VerbalCodeAi?style=social"
                            alt="GitHub forks"></a>
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/issues" target="_blank"><img
                            src="https://img.shields.io/github/issues/vibheksoni/VerbalCodeAi" alt="GitHub issues"></a>
                    <a href="https://github.com/vibheksoni/VerbalCodeAi/blob/master/LICENSE" target="_blank"><img
                            src="https://img.shields.io/github/license/vibheksoni/VerbalCodeAi" alt="GitHub license"></a>
                    <a href="https://www.python.org/downloads/release/python-3116/" target="_blank"><img
                            src="https://img.shields.io/badge/python-3.11.6-blue" alt="Python Version"></a>
                    <a href="https://verbalcode.xyz" target="_blank"><img
                            src="https://img.shields.io/badge/website-verbalcode.xyz-brightgreen" alt="Website"></a>
                </div>
                <div class="ascii-art">
_   _ _______  ______ ______  _______             _______  _____  ______  _______      _______ _____
\  /  |______ |_____/ |_____] |_____| |           |       |     | |     \ |______      |_____|   |  
 \/   |______ |    \_ |_____] |     | |_____      |_____  |_____| |_____/ |______      |     | __|__
    
        [AI Assistant for Code]
                </div>
                <p class="description">
                    A powerful AI-powered code assistant that helps you understand, navigate, and work with codebases
                    more efficiently.
                    VerbalCodeAI uses advanced embedding techniques and LLM integration to provide intelligent code
                    analysis and assistance directly in your terminal.
                </p>
                <div class="cta-buttons">
                    <a href="https://github.com/vibheksoni/VerbalCodeAi" target="_blank" class="btn primary">Get Started
                        (It's Free!)</a>
                    <a href="#features" class="btn secondary">Learn More</a>
                </div>
                
                <div class="discord-banner">
                    <h3>Join Our Discord Community!</h3>
                    <p>We're looking for help setting up and moderating our server. If you're experienced with Discord setup, your assistance would be greatly appreciated!</p>
                    <a href="https://discord.gg/KpjSDEwWCF" target="_blank" class="btn primary">Join Discord</a>
                </div>
            </div>
        </div>
    </header>

    <section id="features">
        <div class="container">
            <h2>‚ú® Features</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h3>üîç Intelligent Code Search</h3>
                    <p>Find relevant code snippets using natural language queries</p>
                </div>
                <div class="feature-card">
                    <h3>üìä Code Analysis</h3>
                    <p>Get insights about your codebase structure and dependencies</p>
                </div>
                <div class="feature-card">
                    <h3>ü§ñ Agent Mode</h3>
                    <p>Let the AI explore and understand your codebase using various tools</p>
                </div>
                <div class="feature-card">
                    <h3>üí¨ Chat with AI</h3>
                    <p>Ask questions about your code and get detailed explanations</p>
                </div>
                <div class="feature-card">
                    <h3>üåê Web Search Integration</h3>
                    <p>Search the web for code-related information without leaving the terminal</p>
                </div>
                <div class="feature-card">
                    <h3>üß† Memory System</h3>
                    <p>The AI remembers important information about your project</p>
                </div>
                <div class="feature-card">
                    <h3>üîÑ Version Control Integration</h3>
                    <p>Analyze git history and changes</p>
                </div>
                <div class="feature-card">
                    <h3>üìù File Description</h3>
                    <p>Generate concise descriptions of code files</p>
                </div>
                <div class="feature-card">
                    <h3>üõ†Ô∏è Command Runner</h3>
                    <p>Execute system commands with AI assistance</p>
                </div>
                <div class="feature-card">
                    <h3>üîå Model Context Protocol (MCP)</h3>
                    <p>Support for the emerging MCP standard for cleaner integration with LLMs</p>
                </div>
                <div class="feature-card">
                    <h3>üñ•Ô∏è HTTP API Server</h3>
                    <p>Run as a server to integrate VerbalCodeAI with your favorite IDE or editor</p>
                </div>
                <div class="feature-card">
                    <h3>üß© IDE Extensions</h3>
                    <p>Integrations with Claude Desktop, Cursor, and more to come</p>
                </div>
            </div>
        </div>
    </section>

    <section id="how-it-works">
        <div class="container">
            <h2>üîç How it Works</h2>

            <div class="process-overview">
                <h3>The Indexing Process</h3>
                <p>When you first use VerbalCodeAI, it indexes your codebase to create searchable resources:</p>

                <div class="index-folders">
                    <div class="folder-item">
                        <h4><code>.index/descriptions</code></h4>
                        <p>Generates a txt file for each file containing a short description of the file</p>
                    </div>
                    <div class="folder-item">
                        <h4><code>.index/embeddings</code></h4>
                        <p>Generates a json file for each file containing the code chunk and embeddings</p>
                    </div>
                    <div class="folder-item">
                        <h4><code>.index/metadata</code></h4>
                        <p>Generates a json file for each file containing hash of file, line numbers, etc.</p>
                    </div>
                    <div class="folder-item">
                        <h4><code>.index/project_description.json</code></h4>
                        <p>Has a description of the project name, tech stack, and a summary of it</p>
                    </div>
                </div>
            </div>

            <div class="chat-modes">
                <h3>Chat Modes</h3>
                <p>VerbalCodeAI offers three powerful ways to interact with your code:</p>

                <div class="mode-grid">
                    <div class="mode-card">
                        <h4>üí¨ Chat with AI</h4>
                        <ol>
                            <li>You type a question about your code.</li>
                            <li>The AI searches for relevant files and project info.</li>
                            <li>It uses its memory to recall past conversations and context.</li>
                            <li>The AI generates a direct, conversational answer, referencing code, files, or project
                                details as needed.</li>
                            <li>You can continue the conversation or ask follow-up questions.</li>
                        </ol>
                    </div>

                    <div class="mode-card">
                        <h4>üöÄ Max Chat Mode</h4>
                        <ol>
                            <li>You ask a question (like in Chat with AI).</li>
                            <li>The AI finds the most relevant files for your question.</li>
                            <li>It sends the full content of those files to the AI model, giving the AI maximum
                                context.</li>
                            <li>The AI generates a highly detailed, context-rich answer, useful for complex questions,
                                code reviews, or debugging.</li>
                            <li>You get a thorough response, with all relevant code considered.</li>
                        </ol>
                    </div>

                    <div class="mode-card full-width">
                        <h4>ü§ñ Agent Mode</h4>
                        <div class="agent-mode-container">
                            <div class="agent-diagram">
                                <div class="diagram-item step-1">
                                    <div class="diagram-icon">üß†</div>
                                    <div class="diagram-content">
                                        <h5>Plan</h5>
                                        <p>Understand your request and decide which tools to use</p>
                                    </div>
                                </div>
                                <div class="diagram-arrow">‚Üí</div>
                                <div class="diagram-item step-2">
                                    <div class="diagram-icon">üîç</div>
                                    <div class="diagram-content">
                                        <h5>Explore</h5>
                                        <p>Use specialized tools to search, read, and analyze your code</p>
                                    </div>
                                </div>
                                <div class="diagram-arrow">‚Üí</div>
                                <div class="diagram-item step-3">
                                    <div class="diagram-icon">üí°</div>
                                    <div class="diagram-content">
                                        <h5>Explain</h5>
                                        <p>Synthesize findings into clear, actionable answers</p>
                                    </div>
                                </div>
                            </div>
                            <div class="agent-description">
                                <p>The Agent Mode allows you to interact with your codebase using a powerful AI agent
                                    that uses specialized tools to explore, search, and understand your code.</p>
                                <p>With Agent Mode, you can:</p>
                                <ul>
                                    <li>Instantly find code snippets, functions, or classes</li>
                                    <li>Get explanations for complex code</li>
                                    <li>Analyze dependencies and project structure</li>
                                    <li>Search version history and more</li>
                                </ul>
                                <p>No manual searching‚Äîjust ask, and let the AI do the heavy lifting!</p>
                                
                                <div class="pro-tip">
                                    <h5>üí° Pro Tip</h5>
                                    <p>Agent Mode is the most cost-effective option when using cloud-based LLM providers. It makes fewer API calls compared to Chat Mode, which helps avoid rate limits and reduces costs. For the best experience with minimal expenses, consider using Agent Mode when working with paid API services.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="getting-started">
        <div class="container">
            <h2>üöÄ Getting Started</h2>

            <h3>Prerequisites</h3>
            <ul>
                <li>Python 3.11.6 (tested and recommended version)</li>
                <li><a href="https://ollama.com/download" target="_blank">Ollama</a> (for local model execution)</li>
            </ul>

            <div class="note">
                <strong>Note:</strong> The application has been specifically tested with Python 3.11.6 on Windows.
                While it may work with other versions, for the best experience, we recommend using the tested
                version.
            </div>

            <h3>Installation</h3>

            <h4>Windows</h4>
            <div class="code-block">
                <pre><code>git clone https://github.com/vibheksoni/VerbalCodeAi.git
cd VerbalCodeAi
setup_windows.bat</code></pre>
            </div>

            <h4>Linux/macOS</h4>
            <div class="code-block">
                <pre><code>git clone https://github.com/vibheksoni/VerbalCodeAi.git
cd VerbalCodeAi
chmod +x setup_linux.sh
./setup_linux.sh</code></pre>
            </div>

            <h3>Manual Installation</h3>
            <p>If you prefer to set up manually:</p>
            <ol>
                <li>
                    Create a virtual environment:
                    <div class="code-block">
                        <pre><code>python -m venv venv</code></pre>
                    </div>
                </li>
                <li>
                    Activate the virtual environment:
                    <ul>
                        <li>Windows: <code>venv\Scripts\activate</code></li>
                        <li>Linux/macOS: <code>source venv/bin/activate</code></li>
                    </ul>
                </li>
                <li>
                    Install dependencies:
                    <div class="code-block">
                        <pre><code>pip install -r requirements.txt</code></pre>
                    </div>
                </li>
                <li>Create a <code>.env</code> file with your configuration (see <code>.env.example</code> for
                        reference)</li>
            </ol>

            <h3>Usage</h3>

            <h4>Starting the Application</h4>
            <p>After installation, activate your virtual environment and run:</p>
            <div class="code-block">
                <pre><code>python app.py</code></pre>
            </div>

            <h4>Indexing a Project</h4>
            <p>When you first start VerbalCodeAI, you'll be prompted to select a directory to index. This process
                analyzes your codebase and creates embeddings for efficient searching.</p>

            <h4>Main Menu Options</h4>
            <ul>
                <li><strong>Chat with AI</strong>: Ask questions about your code</li>
                <li><strong>Agent Mode</strong>: Use AI with tools to explore your codebase</li>
                <li><strong>Reindex Project</strong>: Update the index after code changes</li>
                <li><strong>Project Info</strong>: View information about the indexed project</li>
                <li><strong>Settings</strong>: Configure application settings</li>
                <li><strong>Exit</strong>: Quit the application</li>
            </ul>
        </div>
    </section>

    <section id="agent-tools">
        <div class="container">
            <h2>Agent Mode Tools</h2>
            <p>Agent Mode provides access to powerful tools:</p>

            <div class="tools-grid">
                <div class="tool-category">
                    <h3>Search Tools</h3>
                    <ul>
                        <li><code>embed_search</code></li>
                        <li><code>semantic_search</code></li>
                        <li><code>grep</code></li>
                        <li><code>regex_advanced_search</code></li>
                        <li><code>file_type_search</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>File Tools</h3>
                    <ul>
                        <li><code>read_file</code></li>
                        <li><code>file_stats</code></li>
                        <li><code>directory_tree</code></li>
                        <li><code>get_file_description</code></li>
                        <li><code>get_file_metadata</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Code Analysis</h3>
                    <ul>
                        <li><code>find_functions</code></li>
                        <li><code>find_classes</code></li>
                        <li><code>find_usage</code></li>
                        <li><code>cross_reference</code></li>
                        <li><code>code_analysis</code></li>
                        <li><code>get_functions</code></li>
                        <li><code>get_classes</code></li>
                        <li><code>get_variables</code></li>
                        <li><code>get_imports</code></li>
                        <li><code>explain_code</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Version Control</h3>
                    <ul>
                        <li><code>git_history</code></li>
                        <li><code>version_control_search</code></li>
                        <li><code>search_imports</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Project Tools</h3>
                    <ul>
                        <li><code>get_project_description</code></li>
                        <li><code>get_instructions</code></li>
                        <li><code>create_instructions_template</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Memory Tools</h3>
                    <ul>
                        <li><code>add_memory</code></li>
                        <li><code>get_memories</code></li>
                        <li><code>search_memories</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>System Tools</h3>
                    <ul>
                        <li><code>run_command</code></li>
                        <li><code>read_terminal</code></li>
                        <li><code>kill_terminal</code></li>
                        <li><code>list_terminals</code></li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Helper Tools</h3>
                    <ul>
                        <li><code>ask_buddy</code> (with context-aware second opinions)</li>
                    </ul>
                </div>

                <div class="tool-category">
                    <h3>Web Tools</h3>
                    <ul>
                        <li><code>google_search</code></li>
                        <li><code>ddg_search</code></li>
                        <li><code>bing_news_search</code></li>
                        <li><code>fetch_webpage</code></li>
                        <li><code>get_base_knowledge</code></li>
                    </ul>
                </div>
            </div>
        </div>    </section>

    <section id="integrations">
        <div class="container">
            <h2>üîå HTTP API Server</h2>
            <p>VerbalCodeAI includes a built-in HTTP API server for integrating with external applications and services.</p>
            
            <h3>Starting the HTTP API Server</h3>
            <p>You can start the HTTP API server with the <code>--http</code> command-line option:</p>
            <div class="code-block">
                <pre><code>python app.py --http</code></pre>
            </div>
            <p>This will start the application with both the terminal UI and the HTTP API server running simultaneously.</p>
            
            <h3>API Endpoints</h3>
            <p>The HTTP API server exposes several endpoints:</p>
            <div class="code-block">
                <pre><code>GET    /api/health             - Health check endpoint
POST   /api/initialize         - Initialize a directory
POST   /api/ask                - Ask a question about the code
POST   /api/index/start        - Start indexing a directory
GET    /api/index/status       - Get indexing status</code></pre>
            </div>
            
            <h3>Example Usage</h3>
            <p>Here's an example of how to use the API with cURL:</p>
            <div class="code-block">
                <pre><code>curl -X POST http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What does the main function do in this project?"}'</code></pre>
            </div>
            
            <div class="note">
                <strong>Note:</strong> The HTTP API server is designed for local use by default. If you need to expose it to other machines, configure the host and port appropriately in your environment configuration.
            </div>
        </div>
    </section>

    <section id="mcp-integration">
        <div class="container">
            <h2>ü§ù MCP Integration</h2>
            <p>VerbalCodeAI supports the Model Context Protocol (MCP), allowing you to connect it to Claude Desktop and other MCP-compatible AI assistants. This integration enables Claude to directly interact with your codebase, providing a powerful AI-assisted development experience.</p>

            <div class="image-gallery">
                <img src="assets/images/MCP Showcase.PNG" alt="MCP Integration with Claude Desktop"
                    class="gallery-image">
                <img src="assets/images/MCP Showcase 2.PNG" alt="MCP Showcase - Example 2" class="gallery-image">
            </div>

            <h3>Setting Up the MCP Server</h3>
            <p>The MCP server wraps the HTTP API server and provides tools for Claude to interact with VerbalCodeAI. Here's how to set it up:</p>
            <ol>
                <li>
                    <strong>Start the HTTP API Server</strong>:
                    <p>First, start the HTTP API server if it's not already running:</p>
                    <div class="code-block">
                        <pre><code>python app.py --serve [PORT]</code></pre>
                    </div>
                    <p>Where <code>[PORT]</code> is the port number you want the server to listen on (default is 8000).</p>
                </li>
                <li>
                    <strong>Start the MCP Server</strong>:
                    <p>In a new terminal window, start the MCP server:</p>
                    <div class="code-block">
                        <pre><code>python mcp_server.py</code></pre>
                    </div>
                    <p>The MCP server will automatically check if the HTTP API server is running and start it if needed.</p>
                </li>
                <li>
                    <strong>Configure the MCP Server (Optional)</strong>:
                    <p>You can configure the MCP server by setting the following environment variables in your <code>.env</code> file:</p>
                    <div class="code-block">
                        <pre><code>MCP_API_URL=http://localhost:8000  # URL of the HTTP API server
MCP_HTTP_PORT=8000               # Port to run the HTTP API server on</code></pre>
                    </div>
                </li>
            </ol>

            <h3>Using with Claude Desktop</h3>
            <p>To use VerbalCodeAI with Claude Desktop:</p>
            <ol>
                <li>
                    <strong>Install Dependencies</strong>:
                    <p>Ensure all necessary dependencies are installed by running the following command in the repository's root directory:</p>
                    <div class="code-block">
                        <pre><code>pip install -r requirements.txt</code></pre>
                    </div>
                </li>
                <li>
                    <strong>Install the MCP Server in Claude Desktop</strong>:
                    <p>(Instructions for this step would typically involve placing the server files in a specific directory or using a Claude Desktop interface if available. Refer to Claude Desktop documentation for specifics.)</p>
                    <p>Restart Claude Desktop for the changes to take effect.</p>
                </li>
                <li>
                    <strong>Open Claude Desktop</strong>:
                    <ul>
                        <li>Launch Claude Desktop</li>
                        <li>Select "VerbalCodeAI" from the list of available tools</li>
                    </ul>
                </li>
                <li>
                    <strong>Initialize a Project</strong>:
                    <p>In Claude Desktop, you can now use the following tools:</p>
                    <div class="code-block">
                        <pre><code>set_api_url(url: str) -> str
health_check() -> Dict[str, str]
start_http_server_tool(port: int = None) -> Dict[str, str]
initialize_directory(directory_path: str) -> Dict[str, str]
ask_agent(question: str) -> Dict[str, str]
start_indexing(directory_path: str) -> Dict[str, str]
get_indexing_status() -> Dict[str, str]</code></pre>
                    </div>
                </li>
            </ol>

            <h3>Using with Cursor</h3>
            <p><a href="https://cursor.sh/" target="_blank">Cursor</a> is an AI-powered code editor that supports MCP. To use VerbalCodeAI with Cursor:</p>
            <ol>
                <li><strong>Install Cursor</strong> if you haven't already from <a href="https://cursor.sh/" target="_blank">cursor.sh</a></li>
                <li>
                    <strong>Start the MCP Server</strong>:
                    <div class="code-block">
                        <pre><code>python mcp_server.py</code></pre>
                    </div>
                </li>
                <li>
                    <strong>Connect Cursor to the MCP Server</strong>:
                    <ul>
                        <li>Open Cursor</li>
                        <li>Select "VerbalCodeAI" from the list of available tools (refer to Cursor documentation for specific steps).</li>
                    </ul>
                </li>
                <li>
                    <strong>Use VerbalCodeAI in Cursor</strong>:
                    <ul>
                        <li>Open your project in Cursor</li>
                        <li>You can ask questions about your codebase, get explanations, and more.</li>
                    </ul>
                </li>
            </ol>
        </div>
    </section>

    <section id="configuration">
        <div class="container">
            <h2>‚öôÔ∏è Configuration</h2>
            <p>VerbalCodeAI can be configured through the <code>.env</code> file:</p><div class="code-block">
                <pre><code># Provider can be: ollama, google, openai, anthropic, groq, or openrouter
AI_CHAT_PROVIDER=ollama
AI_EMBEDDING_PROVIDER=ollama
AI_DESCRIPTION_PROVIDER=ollama
AI_AGENT_BUDDY_PROVIDER=ollama

# API Keys for each functionality (only needed if using that provider)
# The same key will be used for the selected provider in each category
AI_CHAT_API_KEY=None
AI_EMBEDDING_API_KEY=None
AI_DESCRIPTION_API_KEY=None
AI_AGENT_BUDDY_API_KEY=None

# Model names for each provider
# For ollama: llama2, codellama, mistral, etc. (embedding)
# For OpenAI: gpt-4, gpt-3.5-turbo, text-embedding-ada-002 (embedding)
# For OpenRouter: anthropic/claude-3-opus, openai/gpt-4-turbo, google/gemini-pro, etc.
# For Google: gemini-pro, gemini-pro-vision
# For Anthropic: claude-3-5-sonnet-latest, claude-3-opus-20240229, claude-3-haiku-20240307
# For Groq: llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768
CHAT_MODEL=llama2
EMBEDDING_MODEL=all-minilm:33m
DESCRIPTION_MODEL=llama2
AI_AGENT_BUDDY_MODEL=llama3.2

# Optional: Site information for OpenRouter rankings
SITE_URL=http://localhost:3000
SITE_NAME=Local Development

# Performance settings (LOW, MEDIUM, MAX)
# LOW: Minimal resource usage, suitable for low-end systems
# MEDIUM: Balanced resource usage, suitable for most systems
# MAX: Maximum resource usage, suitable for high-end systems
PERFORMANCE_MODE=MEDIUM
# Maximum number of threads to use (will be calculated automatically if not set)
MAX_THREADS=16
# Cache size for embedding queries (higher values use more memory but improve performance)
EMBEDDING_CACHE_SIZE=1000
# Similarity threshold for embedding search (lower values return more results but may be less relevant)
EMBEDDING_SIMILARITY_THRESHOLD=0.05

# UI Settings
# Enable/disable markdown rendering (TRUE/FALSE)
ENABLE_MARKDOWN_RENDERING=TRUE
# Show thinking blocks in AI responses (TRUE/FALSE)
SHOW_THINKING_BLOCKS=FALSE
# Enable streaming mode for AI responses (TRUE/FALSE) # Tends to be slower for some reason # Broken for openrouter TODO: Fix this at some point !
ENABLE_STREAMING_MODE=FALSE
# Enable chat logging to save conversations (TRUE/FALSE)
CHAT_LOGS=FALSE
# Enable memory for AI conversations (TRUE/FALSE)
MEMORY_ENABLED=TRUE
# Maximum number of memory items to store
MAX_MEMORY_ITEMS=10
# Execute commands without confirmation (TRUE/FALSE)
# When FALSE, the user will be prompted to confirm before executing any command
# When TRUE, commands will execute automatically without confirmation
COMMANDS_YOLO=FALSE

# HTTP API Server Settings
# Allow connections from any IP address (TRUE/FALSE)
# When FALSE, the server only accepts connections from localhost (127.0.0.1)
# When TRUE, the server accepts connections from any IP address (0.0.0.0)
# WARNING: Setting this to TRUE may expose your API to the internet
HTTP_ALLOW_ALL_ORIGINS=FALSE

# MCP Server Settings
# URL of the HTTP API server
MCP_API_URL=http://localhost:8000
# Port to run the HTTP API server on
MCP_HTTP_PORT=8000
</code></pre>
            </div><h3>Supported LLM Providers</h3>
            <ul style="list-style-type: none; padding-left: 0;">
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://images.seeklogo.com/logo-png/59/1/ollama-logo-png_seeklogo-593420.png" alt="Ollama logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Ollama</strong>: Local models (default)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://logos-world.net/wp-content/uploads/2023/05/Google-Bard-AI-Logo.png" alt="Google AI logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Google AI</strong>: Cloud-based models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/openai-old-logo.png?quality=90&strip=all&crop=7.8125%2C0%2C84.375%2C100&w=2400" alt="OpenAI logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>OpenAI</strong>: OpenAI models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcROScdzQQ7P9TpyyBE4qlB43zKKpesGArmB1w&s" alt="Anthropic logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Anthropic</strong>: Claude 3 models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRHVsO5kFrri_uqZdlB6mACC2bdyyy6D0bYag&s" alt="Groq logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>Groq</strong>: Fast inference for Mixtral and LLama models (requires API key)</div>
                </li>
                <li style="display: flex; align-items: center; padding: 12px; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
                    <img src="https://pbs.twimg.com/profile_images/1682268668321726464/NEb6_n7n_400x400.jpg" alt="OpenRouter logo" style="height: 36px; width: 36px; object-fit: contain; margin-right: 12px; border-radius: 4px;">
                    <div><strong>OpenRouter</strong>: Various cloud models (requires API key)</div>
                </li>
            </ul>
            
            <div class="provider-details">
                <div class="provider-card">
                    <h4>Recommended Ollama Setup</h4>
                    <p>For the best local experience without any API costs, the developer recommends using these Ollama models:</p>
                    <ul>
                        <li><strong>Chat/Description</strong>: <code>gemma3</code> - Google's Gemma 3 model provides excellent code understanding and generation</li>
                        <li><strong>Embeddings</strong>: <code>all-minilm</code> - Efficient and accurate embeddings for code search and retrieval</li>
                    </ul>
                    <div class="code-block">
                        <pre><code># Install the recommended models
ollama pull gemma3
ollama pull all-minilm

# Configure in .env
AI_CHAT_PROVIDER=ollama
AI_EMBEDDING_PROVIDER=ollama
AI_DESCRIPTION_PROVIDER=ollama
CHAT_MODEL=gemma3
EMBEDDING_MODEL=all-minilm:33m
DESCRIPTION_MODEL=gemma3</code></pre>
                    </div>
                </div>

                <div class="provider-card">
                    <h4>Anthropic Claude Models</h4>
                    <p>Anthropic's Claude models are particularly strong at understanding and generating code. Available models include:</p>
                    <ul>
                        <li><strong>claude-3-5-sonnet-latest</strong>: Latest version of Claude 3.5 Sonnet, excellent balance of performance and speed</li>
                        <li><strong>claude-3-opus-20240229</strong>: Most powerful Claude model with advanced reasoning capabilities</li>
                        <li><strong>claude-3-haiku-20240307</strong>: Fastest and most cost-effective Claude model</li>
                    </ul>
                    <p>Note: Anthropic does not provide embedding capabilities, so you'll need to use a different provider for embeddings.</p>
                </div>

                <div class="provider-card">
                    <h4>Groq Models</h4>
                    <p>Groq provides ultra-fast inference for popular open-source models. Available models include:</p>
                    <ul>
                        <li><strong>llama3-8b-8192</strong>: Smaller Llama 3 model with 8B parameters, good balance of performance and speed</li>
                        <li><strong>llama3-70b-8192</strong>: Larger Llama 3 model with 70B parameters, excellent reasoning capabilities</li>
                        <li><strong>mixtral-8x7b-32768</strong>: Mixtral model with 8x7B parameters and 32k context window</li>
                    </ul>
                    <p>Note: Groq does not provide embedding capabilities, so you'll need to use a different provider for embeddings.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="project-structure">
        <div class="container">
            <h2>üß© Project Structure</h2>            <div class="code-block">
                <pre><code>VerbalCodeAi/
‚îú‚îÄ‚îÄ app.py                  # Main application entry point
‚îú‚îÄ‚îÄ mcp_server.py           # MCP server wrapper
‚îú‚îÄ‚îÄ mcp_server_http.py      # HTTP-based MCP server implementation
‚îú‚îÄ‚îÄ mods/                   # Core modules
‚îÇ   ‚îú‚îÄ‚îÄ banners.py          # ASCII art banners
‚îÇ   ‚îú‚îÄ‚îÄ http_api.py         # HTTP API server implementation
‚îÇ   ‚îú‚îÄ‚îÄ llms.py             # LLM integration
‚îÇ   ‚îú‚îÄ‚îÄ terminal_ui.py      # Terminal UI components
‚îÇ   ‚îú‚îÄ‚îÄ terminal_utils.py   # Terminal utilities
‚îÇ   ‚îî‚îÄ‚îÄ code/               # Code processing modules
‚îÇ       ‚îú‚îÄ‚îÄ agent_mode.py   # Agent mode implementation
‚îÇ       ‚îú‚îÄ‚îÄ decisions.py    # AI decision making
‚îÇ       ‚îú‚îÄ‚îÄ directory.py    # Directory structure handling
‚îÇ       ‚îú‚îÄ‚îÄ embed.py        # Embedding generation and search
‚îÇ       ‚îú‚îÄ‚îÄ indexer.py      # File indexing
‚îÇ       ‚îú‚îÄ‚îÄ memory.py       # Memory management
‚îÇ       ‚îú‚îÄ‚îÄ terminal.py     # Terminal command execution
‚îÇ       ‚îî‚îÄ‚îÄ tools.py        # Agent tools
‚îú‚îÄ‚îÄ integrations/           # IDE and tool integrations
‚îÇ   ‚îú‚îÄ‚îÄ claude/             # Claude Desktop integration
‚îÇ   ‚îú‚îÄ‚îÄ cursor/             # Cursor editor integration
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Integration documentation
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ setup_windows.bat       # Windows setup script
‚îî‚îÄ‚îÄ setup_linux.sh          # Linux setup script</code></pre>
            </div>
        </div>
    </section>    <section id="community">
        <div class="container">
            <h2>üë• Community</h2>
            <p>Join our growing community of developers using VerbalCodeAI!</p>
            
            <div class="discord-card">
                <h3>Discord Server</h3>
                <p>Join our Discord server to:</p>
                <ul>
                    <li>Get help with installation and configuration</li>
                    <li>Share your use cases and tips</li>
                    <li>Contribute to the project</li>
                    <li>Connect with other developers using VerbalCodeAI</li>
                    <li>Get early access to new features</li>
                </ul>
                <a href="https://discord.gg/KpjSDEwWCF" target="_blank" class="btn primary">Join Discord</a>
            </div>
        </div>
    </section>

    <section id="contributing">
        <div class="container">
            <h2>ü§ù Contributing</h2>
            <p>Contributions are welcome! Please feel free to submit a Pull Request.</p>
            <ol>
                <li>Fork the repository</li>
                <li>Create your feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
                <li>Commit your changes (<code>git commit -m 'Add some amazing feature'</code>)</li>
                <li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li>
                <li>Open a Pull Request</li>
            </ol>

            <h3>Areas Where Help is Needed</h3>
            <ul>
                <li><strong>IDE Integrations</strong>: Help build plugins for VSCode, Neovim, and other editors</li>
                <li><strong>Documentation</strong>: Improve guides and examples</li>
                <li><strong>Testing</strong>: Help test on different platforms and setups</li>
                <li><strong>Feature Development</strong>: Implement new tools and capabilities</li>
            </ul>
        </div>
    </section>

    <section id="license">
        <div class="container">
            <h2>üìù License</h2>
            <p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
        </div>
    </section>

    <section id="links">
        <div class="container">
            <h2>üîó Links</h2>
            <ul>
                <li><a href="https://github.com/vibheksoni/VerbalCodeAi" target="_blank">GitHub Repository</a></li>
                <li><a href="https://github.com/vibheksoni/VerbalCodeAi/issues" target="_blank">Report Issues</a></li>
            </ul>
        </div>
    </section>

    <section id="acknowledgements">
        <div class="container">
            <h2>üôè Acknowledgements</h2>
            <ul></ul>
                <li><a href="https://ollama.com/" target="_blank">Ollama</a> for local model execution</li>
                <li><a href="https://tree-sitter.github.io/tree-sitter/" target="_blank">Tree-sitter</a> for code
                    parsing</li>
                <li>All the open-source libraries that make this project possible</li>
            </ul>
        </div>
    </section>

    <section id="visual-showcase">
        <div class="container">
            <h2>üé¨ Visual Showcase</h2>

            <div class="image-slider">
                <h3>Application Screenshots</h3>
                <div class="slider-container">
                    <img src="assets/images/Agent Showcase.png" alt="VerbalCodeAI Screenshot" id="sliderImage" class="w-full rounded-lg shadow-lg mb-4">
                    <div class="slider-controls">
                        <button id="prevImage" class="btn secondary">&#10094; Previous</button>
                        <button id="nextImage" class="btn secondary">Next &#10095;</button>
                    </div>
                    <p id="imageCaption" class="text-center mt-2">Agent Mode Showcase</p>
                </div>
            </div>

            <div class="video-showcase mt-12">
                <h3>Simple Showcase Video</h3>
                <video controls class="w-full rounded-lg shadow-lg" id="showcaseVideo"
                    poster="assets/images/Agent Showcase.png">
                    <source src="assets/images/Simple Showcase Video.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>Made with ‚ù§Ô∏è by <a href="https://github.com/vibheksoni" target="_blank">Vibhek Soni</a></p>
            <p>¬© 2024 VerbalCodeAI. All rights reserved.</p>
        </div>
    </footer>

    <script src="assets/js/animations.js"></script>
</body>

</html>